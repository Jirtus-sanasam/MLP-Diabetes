{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jirtus-sanasam/MLP-Diabetes/blob/main/Diabetes7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cqHEjm0KZedz"
      },
      "outputs": [],
      "source": [
        "# Initial import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NS3LcfSGZocj"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/diabetes_data2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the independent and dependent variable\n",
        "\n",
        "X = df.drop(\"Outcome\", axis=1)\n",
        "Y = df['Outcome']"
      ],
      "metadata": {
        "id": "4_GOrQa4n6UA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split full dataset into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=Y  # important for imbalanced medical data\n",
        ")\n"
      ],
      "metadata": {
        "id": "9I1qrhdCn_aW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split training data into train and validation\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(\n",
        "    X_train, Y_train,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=Y_train\n",
        ")\n"
      ],
      "metadata": {
        "id": "4vGXEbnBoCuA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit only on training data\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Transform validation and test data\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "I9HYs7w-oHAf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train = np.array(Y_train)\n",
        "Y_val = np.array(Y_val)\n",
        "Y_test = np.array(Y_test)\n"
      ],
      "metadata": {
        "id": "UJZMkduzpFa1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data for GA hyperparameter tuning\n",
        "X_ga_train = X_train_scaled\n",
        "Y_ga_train = Y_train\n",
        "\n",
        "X_ga_val = X_val_scaled\n",
        "Y_ga_val = Y_val\n"
      ],
      "metadata": {
        "id": "fybAE2SupKKX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Diabetes Prediction using MLP with Nested Genetic Algorithm Optimization\n",
        "=========================================================================\n",
        "\n",
        "Workflow:\n",
        "1. Outer GA (Meta-GA): Optimizes GA hyperparameters\n",
        "2. Inner GA: Optimizes MLP hyperparameters using parameters from Outer GA\n",
        "3. MLP: Trains and predicts diabetes using hyperparameters from Inner GA\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "class MLPGeneticAlgorithm:\n",
        "    \"\"\"Inner GA: Optimizes MLP hyperparameters\"\"\"\n",
        "\n",
        "    def __init__(self, X_train, y_train, X_val, y_val,\n",
        "                 population_size=20, generations=15,\n",
        "                 mutation_rate=0.1, crossover_rate=0.8):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_val = X_val\n",
        "        self.y_val = y_val\n",
        "        self.population_size = population_size\n",
        "        self.generations = generations\n",
        "        self.mutation_rate = mutation_rate\n",
        "        self.crossover_rate = crossover_rate\n",
        "\n",
        "        # MLP hyperparameter search space\n",
        "        self.param_ranges = {\n",
        "            'hidden_layer_1': (10, 200),      # neurons in first hidden layer\n",
        "            'hidden_layer_2': (5, 150),       # neurons in second hidden layer\n",
        "            'learning_rate_init': (0.0001, 0.1),  # learning rate\n",
        "            'alpha': (0.0001, 0.01),          # L2 regularization\n",
        "            'batch_size': (16, 128)           # batch size\n",
        "        }\n",
        "\n",
        "        self.best_individual = None\n",
        "        self.best_fitness = -np.inf\n",
        "        self.fitness_history = []\n",
        "\n",
        "    def create_individual(self):\n",
        "        \"\"\"Create a random MLP configuration\"\"\"\n",
        "        individual = {\n",
        "            'hidden_layer_1': np.random.randint(\n",
        "                self.param_ranges['hidden_layer_1'][0],\n",
        "                self.param_ranges['hidden_layer_1'][1]\n",
        "            ),\n",
        "            'hidden_layer_2': np.random.randint(\n",
        "                self.param_ranges['hidden_layer_2'][0],\n",
        "                self.param_ranges['hidden_layer_2'][1]\n",
        "            ),\n",
        "            'learning_rate_init': np.random.uniform(\n",
        "                self.param_ranges['learning_rate_init'][0],\n",
        "                self.param_ranges['learning_rate_init'][1]\n",
        "            ),\n",
        "            'alpha': np.random.uniform(\n",
        "                self.param_ranges['alpha'][0],\n",
        "                self.param_ranges['alpha'][1]\n",
        "            ),\n",
        "            'batch_size': np.random.randint(\n",
        "                self.param_ranges['batch_size'][0],\n",
        "                self.param_ranges['batch_size'][1]\n",
        "            )\n",
        "        }\n",
        "        return individual\n",
        "\n",
        "    def evaluate_fitness(self, individual):\n",
        "        \"\"\"Evaluate MLP with given hyperparameters\"\"\"\n",
        "        try:\n",
        "            mlp = MLPClassifier(\n",
        "                hidden_layer_sizes=(\n",
        "                    individual['hidden_layer_1'],\n",
        "                    individual['hidden_layer_2']\n",
        "                ),\n",
        "                learning_rate_init=individual['learning_rate_init'],\n",
        "                alpha=individual['alpha'],\n",
        "                batch_size=individual['batch_size'],\n",
        "                max_iter=200,\n",
        "                random_state=42,\n",
        "                early_stopping=True,\n",
        "                validation_fraction=0.1\n",
        "            )\n",
        "\n",
        "            mlp.fit(self.X_train, self.y_train)\n",
        "            y_pred = mlp.predict(self.X_val)\n",
        "\n",
        "            # Fitness is a combination of accuracy and F1 score\n",
        "            accuracy = accuracy_score(self.y_val, y_pred)\n",
        "            f1 = f1_score(self.y_val, y_pred, average='weighted')\n",
        "            fitness = 0.6 * accuracy + 0.4 * f1\n",
        "\n",
        "            return fitness\n",
        "        except Exception as e:\n",
        "            return 0.0  # Return low fitness if model fails\n",
        "\n",
        "    def selection(self, population, fitness_scores):\n",
        "        \"\"\"Tournament selection\"\"\"\n",
        "        tournament_size = 3\n",
        "        selected = []\n",
        "\n",
        "        for _ in range(len(population)):\n",
        "            tournament_idx = np.random.choice(\n",
        "                len(population), tournament_size, replace=False\n",
        "            )\n",
        "            tournament_fitness = [fitness_scores[i] for i in tournament_idx]\n",
        "            winner_idx = tournament_idx[np.argmax(tournament_fitness)]\n",
        "            selected.append(population[winner_idx].copy())\n",
        "\n",
        "        return selected\n",
        "\n",
        "    def crossover(self, parent1, parent2):\n",
        "        \"\"\"Single-point crossover\"\"\"\n",
        "        if np.random.random() > self.crossover_rate:\n",
        "            return parent1.copy(), parent2.copy()\n",
        "\n",
        "        child1, child2 = parent1.copy(), parent2.copy()\n",
        "\n",
        "        # Randomly choose which parameters to swap\n",
        "        for key in parent1.keys():\n",
        "            if np.random.random() < 0.5:\n",
        "                child1[key], child2[key] = child2[key], child1[key]\n",
        "\n",
        "        return child1, child2\n",
        "\n",
        "    def mutate(self, individual):\n",
        "        \"\"\"Gaussian mutation for continuous, random reset for discrete\"\"\"\n",
        "        mutated = individual.copy()\n",
        "\n",
        "        for key, value in mutated.items():\n",
        "            if np.random.random() < self.mutation_rate:\n",
        "                if key in ['hidden_layer_1', 'hidden_layer_2', 'batch_size']:\n",
        "                    # Discrete parameters\n",
        "                    mutated[key] = np.random.randint(\n",
        "                        self.param_ranges[key][0],\n",
        "                        self.param_ranges[key][1]\n",
        "                    )\n",
        "                else:\n",
        "                    # Continuous parameters - Gaussian mutation\n",
        "                    mutation = np.random.normal(0, 0.1 * value)\n",
        "                    mutated[key] = np.clip(\n",
        "                        value + mutation,\n",
        "                        self.param_ranges[key][0],\n",
        "                        self.param_ranges[key][1]\n",
        "                    )\n",
        "\n",
        "        return mutated\n",
        "\n",
        "    def evolve(self):\n",
        "        \"\"\"Run the genetic algorithm\"\"\"\n",
        "        # Initialize population\n",
        "        population = [self.create_individual() for _ in range(self.population_size)]\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Inner GA: Optimizing MLP Hyperparameters\")\n",
        "        print(f\"Population Size: {self.population_size}, Generations: {self.generations}\")\n",
        "        print(f\"Mutation Rate: {self.mutation_rate:.3f}, Crossover Rate: {self.crossover_rate:.3f}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        for generation in range(self.generations):\n",
        "            # Evaluate fitness\n",
        "            fitness_scores = [self.evaluate_fitness(ind) for ind in population]\n",
        "\n",
        "            # Track best individual\n",
        "            max_fitness_idx = np.argmax(fitness_scores)\n",
        "            if fitness_scores[max_fitness_idx] > self.best_fitness:\n",
        "                self.best_fitness = fitness_scores[max_fitness_idx]\n",
        "                self.best_individual = population[max_fitness_idx].copy()\n",
        "\n",
        "            avg_fitness = np.mean(fitness_scores)\n",
        "            self.fitness_history.append((generation, avg_fitness, self.best_fitness))\n",
        "\n",
        "            print(f\"Gen {generation+1:2d} | Avg Fitness: {avg_fitness:.4f} | \"\n",
        "                  f\"Best Fitness: {self.best_fitness:.4f}\")\n",
        "\n",
        "            # Selection\n",
        "            selected = self.selection(population, fitness_scores)\n",
        "\n",
        "            # Crossover and mutation\n",
        "            next_population = []\n",
        "            for i in range(0, len(selected), 2):\n",
        "                parent1 = selected[i]\n",
        "                parent2 = selected[i+1] if i+1 < len(selected) else selected[0]\n",
        "\n",
        "                child1, child2 = self.crossover(parent1, parent2)\n",
        "                child1 = self.mutate(child1)\n",
        "                child2 = self.mutate(child2)\n",
        "\n",
        "                next_population.extend([child1, child2])\n",
        "\n",
        "            # Elitism: keep best individual\n",
        "            next_population[0] = self.best_individual.copy()\n",
        "            population = next_population[:self.population_size]\n",
        "\n",
        "        print(f\"\\nBest MLP Configuration Found:\")\n",
        "        for key, value in self.best_individual.items():\n",
        "            print(f\"  {key}: {value}\")\n",
        "\n",
        "        return self.best_individual, self.best_fitness\n",
        "\n",
        "\n",
        "class MetaGeneticAlgorithm:\n",
        "    \"\"\"Outer GA: Optimizes GA hyperparameters\"\"\"\n",
        "\n",
        "    def __init__(self, X_train, y_train, X_val, y_val,\n",
        "                 population_size=10, generations=5):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_val = X_val\n",
        "        self.y_val = y_val\n",
        "        self.population_size = population_size\n",
        "        self.generations = generations\n",
        "\n",
        "        # GA hyperparameter search space\n",
        "        self.param_ranges = {\n",
        "            'population_size': (10, 40),\n",
        "            'generations': (10, 30),\n",
        "            'mutation_rate': (0.05, 0.3),\n",
        "            'crossover_rate': (0.6, 0.95)\n",
        "        }\n",
        "\n",
        "        self.best_individual = None\n",
        "        self.best_fitness = -np.inf\n",
        "        self.fitness_history = []\n",
        "\n",
        "    def create_individual(self):\n",
        "        \"\"\"Create random GA configuration\"\"\"\n",
        "        individual = {\n",
        "            'population_size': np.random.randint(\n",
        "                self.param_ranges['population_size'][0],\n",
        "                self.param_ranges['population_size'][1]\n",
        "            ),\n",
        "            'generations': np.random.randint(\n",
        "                self.param_ranges['generations'][0],\n",
        "                self.param_ranges['generations'][1]\n",
        "            ),\n",
        "            'mutation_rate': np.random.uniform(\n",
        "                self.param_ranges['mutation_rate'][0],\n",
        "                self.param_ranges['mutation_rate'][1]\n",
        "            ),\n",
        "            'crossover_rate': np.random.uniform(\n",
        "                self.param_ranges['crossover_rate'][0],\n",
        "                self.param_ranges['crossover_rate'][1]\n",
        "            )\n",
        "        }\n",
        "        return individual\n",
        "\n",
        "    def evaluate_fitness(self, individual):\n",
        "        \"\"\"Run Inner GA with these GA parameters and return best MLP performance\"\"\"\n",
        "        inner_ga = MLPGeneticAlgorithm(\n",
        "            self.X_train, self.y_train, self.X_val, self.y_val,\n",
        "            population_size=individual['population_size'],\n",
        "            generations=individual['generations'],\n",
        "            mutation_rate=individual['mutation_rate'],\n",
        "            crossover_rate=individual['crossover_rate']\n",
        "        )\n",
        "\n",
        "        _, fitness = inner_ga.evolve()\n",
        "        return fitness\n",
        "\n",
        "    def selection(self, population, fitness_scores):\n",
        "        \"\"\"Tournament selection\"\"\"\n",
        "        tournament_size = 2\n",
        "        selected = []\n",
        "\n",
        "        for _ in range(len(population)):\n",
        "            tournament_idx = np.random.choice(\n",
        "                len(population), tournament_size, replace=False\n",
        "            )\n",
        "            tournament_fitness = [fitness_scores[i] for i in tournament_idx]\n",
        "            winner_idx = tournament_idx[np.argmax(tournament_fitness)]\n",
        "            selected.append(population[winner_idx].copy())\n",
        "\n",
        "        return selected\n",
        "\n",
        "    def crossover(self, parent1, parent2):\n",
        "        \"\"\"Uniform crossover\"\"\"\n",
        "        child1, child2 = parent1.copy(), parent2.copy()\n",
        "\n",
        "        for key in parent1.keys():\n",
        "            if np.random.random() < 0.5:\n",
        "                child1[key], child2[key] = child2[key], child1[key]\n",
        "\n",
        "        return child1, child2\n",
        "\n",
        "    def mutate(self, individual):\n",
        "        \"\"\"Gaussian mutation\"\"\"\n",
        "        mutated = individual.copy()\n",
        "        mutation_prob = 0.3\n",
        "\n",
        "        for key, value in mutated.items():\n",
        "            if np.random.random() < mutation_prob:\n",
        "                if key in ['population_size', 'generations']:\n",
        "                    mutated[key] = np.random.randint(\n",
        "                        self.param_ranges[key][0],\n",
        "                        self.param_ranges[key][1]\n",
        "                    )\n",
        "                else:\n",
        "                    mutation = np.random.normal(0, 0.1 * value)\n",
        "                    mutated[key] = np.clip(\n",
        "                        value + mutation,\n",
        "                        self.param_ranges[key][0],\n",
        "                        self.param_ranges[key][1]\n",
        "                    )\n",
        "\n",
        "        return mutated\n",
        "\n",
        "    def evolve(self):\n",
        "        \"\"\"Run the meta genetic algorithm\"\"\"\n",
        "        population = [self.create_individual() for _ in range(self.population_size)]\n",
        "\n",
        "        print(f\"\\n{'#'*60}\")\n",
        "        print(f\"OUTER GA (Meta-GA): Optimizing GA Hyperparameters\")\n",
        "        print(f\"Population Size: {self.population_size}, Generations: {self.generations}\")\n",
        "        print(f\"{'#'*60}\\n\")\n",
        "\n",
        "        for generation in range(self.generations):\n",
        "            print(f\"\\n{'*'*60}\")\n",
        "            print(f\"META-GA Generation {generation+1}/{self.generations}\")\n",
        "            print(f\"{'*'*60}\")\n",
        "\n",
        "            # Evaluate fitness\n",
        "            fitness_scores = []\n",
        "            for idx, ind in enumerate(population):\n",
        "                print(f\"\\nEvaluating GA Config {idx+1}/{len(population)}:\")\n",
        "                print(f\"  Population: {ind['population_size']}, Generations: {ind['generations']}\")\n",
        "                print(f\"  Mutation: {ind['mutation_rate']:.3f}, Crossover: {ind['crossover_rate']:.3f}\")\n",
        "\n",
        "                fitness = self.evaluate_fitness(ind)\n",
        "                fitness_scores.append(fitness)\n",
        "\n",
        "                print(f\"  => Fitness: {fitness:.4f}\")\n",
        "\n",
        "            # Track best\n",
        "            max_fitness_idx = np.argmax(fitness_scores)\n",
        "            if fitness_scores[max_fitness_idx] > self.best_fitness:\n",
        "                self.best_fitness = fitness_scores[max_fitness_idx]\n",
        "                self.best_individual = population[max_fitness_idx].copy()\n",
        "\n",
        "            avg_fitness = np.mean(fitness_scores)\n",
        "            self.fitness_history.append((generation, avg_fitness, self.best_fitness))\n",
        "\n",
        "            print(f\"\\n{'*'*60}\")\n",
        "            print(f\"Meta-GA Gen {generation+1} Summary:\")\n",
        "            print(f\"  Avg Fitness: {avg_fitness:.4f}\")\n",
        "            print(f\"  Best Fitness: {self.best_fitness:.4f}\")\n",
        "            print(f\"{'*'*60}\")\n",
        "\n",
        "            # Evolution\n",
        "            selected = self.selection(population, fitness_scores)\n",
        "\n",
        "            next_population = []\n",
        "            for i in range(0, len(selected), 2):\n",
        "                parent1 = selected[i]\n",
        "                parent2 = selected[i+1] if i+1 < len(selected) else selected[0]\n",
        "\n",
        "                child1, child2 = self.crossover(parent1, parent2)\n",
        "                child1 = self.mutate(child1)\n",
        "                child2 = self.mutate(child2)\n",
        "\n",
        "                next_population.extend([child1, child2])\n",
        "\n",
        "            # Elitism\n",
        "            next_population[0] = self.best_individual.copy()\n",
        "            population = next_population[:self.population_size]\n",
        "\n",
        "        return self.best_individual, self.best_fitness\n",
        "\n",
        "\n",
        "def load_and_prepare_data(filepath=None):\n",
        "    \"\"\"Load and prepare diabetes dataset\"\"\"\n",
        "    if filepath:\n",
        "        # Load custom dataset\n",
        "        data = pd.read_csv(filepath)\n",
        "    else:\n",
        "        # Create sample diabetes dataset (Pima Indians Diabetes style)\n",
        "        print(\"Using sample diabetes dataset...\")\n",
        "        np.random.seed(42)\n",
        "        n_samples = 500\n",
        "\n",
        "        # Generate synthetic features\n",
        "        data = pd.DataFrame({\n",
        "            'Pregnancies': np.random.randint(0, 15, n_samples),\n",
        "            'Glucose': np.random.normal(120, 30, n_samples),\n",
        "            'BloodPressure': np.random.normal(70, 12, n_samples),\n",
        "            'SkinThickness': np.random.normal(29, 10, n_samples),\n",
        "            'Insulin': np.random.normal(140, 80, n_samples),\n",
        "            'BMI': np.random.normal(32, 6, n_samples),\n",
        "            'DiabetesPedigree': np.random.uniform(0.1, 2.5, n_samples),\n",
        "            'Age': np.random.randint(21, 80, n_samples),\n",
        "        })\n",
        "\n",
        "        # Generate outcome based on features (with some logic)\n",
        "        score = (data['Glucose'] * 0.02 +\n",
        "                 data['BMI'] * 0.1 +\n",
        "                 data['Age'] * 0.05 +\n",
        "                 np.random.normal(0, 2, n_samples))\n",
        "        data['Outcome'] = (score > 10).astype(int)\n",
        "\n",
        "    # Separate features and target\n",
        "    X = data.drop('Outcome', axis=1)\n",
        "    y = data['Outcome']\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
        "    )\n",
        "\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val = scaler.transform(X_val)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    print(f\"\\nDataset loaded successfully!\")\n",
        "    print(f\"Training samples: {len(X_train)}\")\n",
        "    print(f\"Validation samples: {len(X_val)}\")\n",
        "    print(f\"Test samples: {len(X_test)}\")\n",
        "    print(f\"Features: {X.shape[1]}\")\n",
        "    print(f\"Class distribution - Class 0: {sum(y==0)}, Class 1: {sum(y==1)}\")\n",
        "\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test, scaler\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution pipeline\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"DIABETES PREDICTION WITH NESTED GENETIC ALGORITHM\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Load data\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test, scaler = load_and_prepare_data()\n",
        "\n",
        "    # Step 1: Run Meta-GA to find best GA hyperparameters\n",
        "    meta_ga = MetaGeneticAlgorithm(\n",
        "        X_train, y_train, X_val, y_val,\n",
        "        population_size=6,  # Small for demonstration, increase for real use\n",
        "        generations=3       # Small for demonstration, increase for real use\n",
        "    )\n",
        "\n",
        "    best_ga_params, meta_fitness = meta_ga.evolve()\n",
        "\n",
        "    print(f\"\\n{'#'*60}\")\n",
        "    print(\"FINAL RESULTS - BEST GA HYPERPARAMETERS FOUND:\")\n",
        "    print(f\"{'#'*60}\")\n",
        "    for key, value in best_ga_params.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "    print(f\"\\nBest validation fitness achieved: {meta_fitness:.4f}\")\n",
        "\n",
        "    # Step 2: Run Inner GA with best GA parameters to find best MLP\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"FINAL RUN: Training MLP with Optimized Hyperparameters\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    final_inner_ga = MLPGeneticAlgorithm(\n",
        "        X_train, y_train, X_val, y_val,\n",
        "        population_size=best_ga_params['population_size'],\n",
        "        generations=best_ga_params['generations'],\n",
        "        mutation_rate=best_ga_params['mutation_rate'],\n",
        "        crossover_rate=best_ga_params['crossover_rate']\n",
        "    )\n",
        "\n",
        "    best_mlp_params, best_fitness = final_inner_ga.evolve()\n",
        "\n",
        "    # Step 3: Train final model and evaluate on test set\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"FINAL MODEL EVALUATION ON TEST SET\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    final_mlp = MLPClassifier(\n",
        "        hidden_layer_sizes=(\n",
        "            best_mlp_params['hidden_layer_1'],\n",
        "            best_mlp_params['hidden_layer_2']\n",
        "        ),\n",
        "        learning_rate_init=best_mlp_params['learning_rate_init'],\n",
        "        alpha=best_mlp_params['alpha'],\n",
        "        batch_size=best_mlp_params['batch_size'],\n",
        "        max_iter=300,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Train on full training + validation set\n",
        "    X_train_full = np.vstack([X_train, X_val])\n",
        "    y_train_full = np.concatenate([y_train, y_val])\n",
        "\n",
        "    final_mlp.fit(X_train_full, y_train_full)\n",
        "    y_pred = final_mlp.predict(X_test)\n",
        "    y_pred_proba = final_mlp.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "    print(f\"\\nTest Set Performance:\")\n",
        "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"  F1 Score: {f1:.4f}\")\n",
        "    print(f\"  ROC AUC:  {auc:.4f}\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"OPTIMIZATION COMPLETE!\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    return {\n",
        "        'best_ga_params': best_ga_params,\n",
        "        'best_mlp_params': best_mlp_params,\n",
        "        'test_accuracy': accuracy,\n",
        "        'test_f1': f1,\n",
        "        'test_auc': auc,\n",
        "        'model': final_mlp,\n",
        "        'scaler': scaler\n",
        "    }\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results = main()"
      ],
      "metadata": {
        "id": "g4VbNKo4pVS8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca512043-c084-406d-d657-f1485ec0d340"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DIABETES PREDICTION WITH NESTED GENETIC ALGORITHM\n",
            "============================================================\n",
            "Using sample diabetes dataset...\n",
            "\n",
            "Dataset loaded successfully!\n",
            "Training samples: 320\n",
            "Validation samples: 80\n",
            "Test samples: 100\n",
            "Features: 8\n",
            "Class distribution - Class 0: 386, Class 1: 114\n",
            "\n",
            "############################################################\n",
            "OUTER GA (Meta-GA): Optimizing GA Hyperparameters\n",
            "Population Size: 6, Generations: 3\n",
            "############################################################\n",
            "\n",
            "\n",
            "************************************************************\n",
            "META-GA Generation 1/3\n",
            "************************************************************\n",
            "\n",
            "Evaluating GA Config 1/6:\n",
            "  Population: 10, Generations: 19\n",
            "  Mutation: 0.292, Crossover: 0.830\n",
            "\n",
            "============================================================\n",
            "Inner GA: Optimizing MLP Hyperparameters\n",
            "Population Size: 10, Generations: 19\n",
            "Mutation Rate: 0.292, Crossover Rate: 0.830\n",
            "============================================================\n",
            "Gen  1 | Avg Fitness: 0.7552 | Best Fitness: 0.7991\n",
            "Gen  2 | Avg Fitness: 0.7706 | Best Fitness: 0.8055\n",
            "Gen  3 | Avg Fitness: 0.7714 | Best Fitness: 0.8055\n",
            "Gen  4 | Avg Fitness: 0.7719 | Best Fitness: 0.8055\n",
            "Gen  5 | Avg Fitness: 0.7757 | Best Fitness: 0.8055\n",
            "Gen  6 | Avg Fitness: 0.7625 | Best Fitness: 0.8055\n",
            "Gen  7 | Avg Fitness: 0.7776 | Best Fitness: 0.8055\n",
            "Gen  8 | Avg Fitness: 0.7532 | Best Fitness: 0.8055\n",
            "Gen  9 | Avg Fitness: 0.7496 | Best Fitness: 0.8055\n",
            "Gen 10 | Avg Fitness: 0.7582 | Best Fitness: 0.8055\n",
            "Gen 11 | Avg Fitness: 0.7722 | Best Fitness: 0.8055\n",
            "Gen 12 | Avg Fitness: 0.7637 | Best Fitness: 0.8171\n",
            "Gen 13 | Avg Fitness: 0.7599 | Best Fitness: 0.8171\n",
            "Gen 14 | Avg Fitness: 0.7796 | Best Fitness: 0.8171\n",
            "Gen 15 | Avg Fitness: 0.7712 | Best Fitness: 0.8171\n",
            "Gen 16 | Avg Fitness: 0.7661 | Best Fitness: 0.8171\n",
            "Gen 17 | Avg Fitness: 0.7713 | Best Fitness: 0.8171\n",
            "Gen 18 | Avg Fitness: 0.7774 | Best Fitness: 0.8171\n",
            "Gen 19 | Avg Fitness: 0.7641 | Best Fitness: 0.8171\n",
            "\n",
            "Best MLP Configuration Found:\n",
            "  hidden_layer_1: 155\n",
            "  hidden_layer_2: 78\n",
            "  learning_rate_init: 0.054713058763241444\n",
            "  alpha: 0.007160569945138232\n",
            "  batch_size: 124\n",
            "  => Fitness: 0.8171\n",
            "\n",
            "Evaluating GA Config 2/6:\n",
            "  Population: 28, Generations: 21\n",
            "  Mutation: 0.200, Crossover: 0.844\n",
            "\n",
            "============================================================\n",
            "Inner GA: Optimizing MLP Hyperparameters\n",
            "Population Size: 28, Generations: 21\n",
            "Mutation Rate: 0.200, Crossover Rate: 0.844\n",
            "============================================================\n",
            "Gen  1 | Avg Fitness: 0.7546 | Best Fitness: 0.7938\n",
            "Gen  2 | Avg Fitness: 0.7579 | Best Fitness: 0.7991\n",
            "Gen  3 | Avg Fitness: 0.7623 | Best Fitness: 0.7991\n",
            "Gen  4 | Avg Fitness: 0.7672 | Best Fitness: 0.8171\n",
            "Gen  5 | Avg Fitness: 0.7680 | Best Fitness: 0.8171\n",
            "Gen  6 | Avg Fitness: 0.7659 | Best Fitness: 0.8171\n",
            "Gen  7 | Avg Fitness: 0.7700 | Best Fitness: 0.8171\n",
            "Gen  8 | Avg Fitness: 0.7614 | Best Fitness: 0.8171\n",
            "Gen  9 | Avg Fitness: 0.7632 | Best Fitness: 0.8171\n",
            "Gen 10 | Avg Fitness: 0.7625 | Best Fitness: 0.8171\n",
            "Gen 11 | Avg Fitness: 0.7609 | Best Fitness: 0.8171\n",
            "Gen 12 | Avg Fitness: 0.7680 | Best Fitness: 0.8171\n",
            "Gen 13 | Avg Fitness: 0.7775 | Best Fitness: 0.8171\n",
            "Gen 14 | Avg Fitness: 0.7653 | Best Fitness: 0.8171\n",
            "Gen 15 | Avg Fitness: 0.7698 | Best Fitness: 0.8171\n",
            "Gen 16 | Avg Fitness: 0.7643 | Best Fitness: 0.8171\n",
            "Gen 17 | Avg Fitness: 0.7646 | Best Fitness: 0.8314\n",
            "Gen 18 | Avg Fitness: 0.7736 | Best Fitness: 0.8314\n",
            "Gen 19 | Avg Fitness: 0.7777 | Best Fitness: 0.8314\n",
            "Gen 20 | Avg Fitness: 0.7746 | Best Fitness: 0.8314\n",
            "Gen 21 | Avg Fitness: 0.7833 | Best Fitness: 0.8314\n",
            "\n",
            "Best MLP Configuration Found:\n",
            "  hidden_layer_1: 91\n",
            "  hidden_layer_2: 103\n",
            "  learning_rate_init: 0.02192642729154795\n",
            "  alpha: 0.0001983168992192679\n",
            "  batch_size: 19\n",
            "  => Fitness: 0.8314\n",
            "\n",
            "Evaluating GA Config 3/6:\n",
            "  Population: 24, Generations: 26\n",
            "  Mutation: 0.098, Crossover: 0.765\n",
            "\n",
            "============================================================\n",
            "Inner GA: Optimizing MLP Hyperparameters\n",
            "Population Size: 24, Generations: 26\n",
            "Mutation Rate: 0.098, Crossover Rate: 0.765\n",
            "============================================================\n",
            "Gen  1 | Avg Fitness: 0.7521 | Best Fitness: 0.8079\n",
            "Gen  2 | Avg Fitness: 0.7593 | Best Fitness: 0.8079\n",
            "Gen  3 | Avg Fitness: 0.7562 | Best Fitness: 0.8079\n",
            "Gen  4 | Avg Fitness: 0.7553 | Best Fitness: 0.8079\n",
            "Gen  5 | Avg Fitness: 0.7548 | Best Fitness: 0.8079\n",
            "Gen  6 | Avg Fitness: 0.7678 | Best Fitness: 0.8079\n",
            "Gen  7 | Avg Fitness: 0.7719 | Best Fitness: 0.8079\n",
            "Gen  8 | Avg Fitness: 0.7713 | Best Fitness: 0.8079\n",
            "Gen  9 | Avg Fitness: 0.7756 | Best Fitness: 0.8079\n",
            "Gen 10 | Avg Fitness: 0.7804 | Best Fitness: 0.8171\n",
            "Gen 11 | Avg Fitness: 0.7900 | Best Fitness: 0.8171\n",
            "Gen 12 | Avg Fitness: 0.7823 | Best Fitness: 0.8171\n",
            "Gen 13 | Avg Fitness: 0.7853 | Best Fitness: 0.8171\n",
            "Gen 14 | Avg Fitness: 0.7941 | Best Fitness: 0.8171\n",
            "Gen 15 | Avg Fitness: 0.8003 | Best Fitness: 0.8171\n",
            "Gen 16 | Avg Fitness: 0.7927 | Best Fitness: 0.8171\n",
            "Gen 17 | Avg Fitness: 0.8000 | Best Fitness: 0.8171\n",
            "Gen 18 | Avg Fitness: 0.7948 | Best Fitness: 0.8171\n",
            "Gen 19 | Avg Fitness: 0.8028 | Best Fitness: 0.8171\n",
            "Gen 20 | Avg Fitness: 0.7938 | Best Fitness: 0.8171\n",
            "Gen 21 | Avg Fitness: 0.7932 | Best Fitness: 0.8171\n",
            "Gen 22 | Avg Fitness: 0.7956 | Best Fitness: 0.8171\n",
            "Gen 23 | Avg Fitness: 0.8045 | Best Fitness: 0.8171\n",
            "Gen 24 | Avg Fitness: 0.7975 | Best Fitness: 0.8171\n",
            "Gen 25 | Avg Fitness: 0.7884 | Best Fitness: 0.8171\n",
            "Gen 26 | Avg Fitness: 0.8039 | Best Fitness: 0.8171\n",
            "\n",
            "Best MLP Configuration Found:\n",
            "  hidden_layer_1: 137\n",
            "  hidden_layer_2: 128\n",
            "  learning_rate_init: 0.07012919010951597\n",
            "  alpha: 0.00353963979615982\n",
            "  batch_size: 76\n",
            "  => Fitness: 0.8171\n",
            "\n",
            "Evaluating GA Config 4/6:\n",
            "  Population: 35, Generations: 11\n",
            "  Mutation: 0.145, Crossover: 0.781\n",
            "\n",
            "============================================================\n",
            "Inner GA: Optimizing MLP Hyperparameters\n",
            "Population Size: 35, Generations: 11\n",
            "Mutation Rate: 0.145, Crossover Rate: 0.781\n",
            "============================================================\n",
            "Gen  1 | Avg Fitness: 0.7581 | Best Fitness: 0.7938\n",
            "Gen  2 | Avg Fitness: 0.7623 | Best Fitness: 0.7991\n",
            "Gen  3 | Avg Fitness: 0.7737 | Best Fitness: 0.8106\n",
            "Gen  4 | Avg Fitness: 0.7758 | Best Fitness: 0.8106\n",
            "Gen  5 | Avg Fitness: 0.7784 | Best Fitness: 0.8106\n",
            "Gen  6 | Avg Fitness: 0.7842 | Best Fitness: 0.8106\n",
            "Gen  7 | Avg Fitness: 0.7835 | Best Fitness: 0.8142\n",
            "Gen  8 | Avg Fitness: 0.7869 | Best Fitness: 0.8142\n",
            "Gen  9 | Avg Fitness: 0.7849 | Best Fitness: 0.8142\n",
            "Gen 10 | Avg Fitness: 0.7840 | Best Fitness: 0.8142\n",
            "Gen 11 | Avg Fitness: 0.7746 | Best Fitness: 0.8142\n",
            "\n",
            "Best MLP Configuration Found:\n",
            "  hidden_layer_1: 72\n",
            "  hidden_layer_2: 24\n",
            "  learning_rate_init: 0.02584431186583385\n",
            "  alpha: 0.00923840820256637\n",
            "  batch_size: 23\n",
            "  => Fitness: 0.8142\n",
            "\n",
            "Evaluating GA Config 5/6:\n",
            "  Population: 22, Generations: 24\n",
            "  Mutation: 0.100, Crossover: 0.744\n",
            "\n",
            "============================================================\n",
            "Inner GA: Optimizing MLP Hyperparameters\n",
            "Population Size: 22, Generations: 24\n",
            "Mutation Rate: 0.100, Crossover Rate: 0.744\n",
            "============================================================\n",
            "Gen  1 | Avg Fitness: 0.7496 | Best Fitness: 0.7910\n",
            "Gen  2 | Avg Fitness: 0.7607 | Best Fitness: 0.7910\n",
            "Gen  3 | Avg Fitness: 0.7666 | Best Fitness: 0.8025\n",
            "Gen  4 | Avg Fitness: 0.7749 | Best Fitness: 0.8079\n",
            "Gen  5 | Avg Fitness: 0.7633 | Best Fitness: 0.8079\n",
            "Gen  6 | Avg Fitness: 0.7624 | Best Fitness: 0.8079\n",
            "Gen  7 | Avg Fitness: 0.7673 | Best Fitness: 0.8079\n",
            "Gen  8 | Avg Fitness: 0.7774 | Best Fitness: 0.8079\n",
            "Gen  9 | Avg Fitness: 0.7750 | Best Fitness: 0.8079\n",
            "Gen 10 | Avg Fitness: 0.7788 | Best Fitness: 0.8079\n",
            "Gen 11 | Avg Fitness: 0.7835 | Best Fitness: 0.8079\n",
            "Gen 12 | Avg Fitness: 0.7827 | Best Fitness: 0.8079\n",
            "Gen 13 | Avg Fitness: 0.7851 | Best Fitness: 0.8100\n",
            "Gen 14 | Avg Fitness: 0.7907 | Best Fitness: 0.8100\n",
            "Gen 15 | Avg Fitness: 0.7903 | Best Fitness: 0.8100\n",
            "Gen 16 | Avg Fitness: 0.7830 | Best Fitness: 0.8100\n",
            "Gen 17 | Avg Fitness: 0.7887 | Best Fitness: 0.8100\n",
            "Gen 18 | Avg Fitness: 0.7922 | Best Fitness: 0.8100\n",
            "Gen 19 | Avg Fitness: 0.7915 | Best Fitness: 0.8142\n",
            "Gen 20 | Avg Fitness: 0.7884 | Best Fitness: 0.8142\n",
            "Gen 21 | Avg Fitness: 0.7980 | Best Fitness: 0.8142\n",
            "Gen 22 | Avg Fitness: 0.7970 | Best Fitness: 0.8142\n",
            "Gen 23 | Avg Fitness: 0.7923 | Best Fitness: 0.8142\n",
            "Gen 24 | Avg Fitness: 0.7842 | Best Fitness: 0.8142\n",
            "\n",
            "Best MLP Configuration Found:\n",
            "  hidden_layer_1: 101\n",
            "  hidden_layer_2: 53\n",
            "  learning_rate_init: 0.06785716265798741\n",
            "  alpha: 0.004805713283643127\n",
            "  batch_size: 83\n",
            "  => Fitness: 0.8142\n",
            "\n",
            "Evaluating GA Config 6/6:\n",
            "  Population: 35, Generations: 10\n",
            "  Mutation: 0.263, Crossover: 0.854\n",
            "\n",
            "============================================================\n",
            "Inner GA: Optimizing MLP Hyperparameters\n",
            "Population Size: 35, Generations: 10\n",
            "Mutation Rate: 0.263, Crossover Rate: 0.854\n",
            "============================================================\n",
            "Gen  1 | Avg Fitness: 0.7486 | Best Fitness: 0.7910\n",
            "Gen  2 | Avg Fitness: 0.7505 | Best Fitness: 0.8055\n",
            "Gen  3 | Avg Fitness: 0.7614 | Best Fitness: 0.8055\n",
            "Gen  4 | Avg Fitness: 0.7566 | Best Fitness: 0.8055\n",
            "Gen  5 | Avg Fitness: 0.7691 | Best Fitness: 0.8142\n",
            "Gen  6 | Avg Fitness: 0.7776 | Best Fitness: 0.8142\n",
            "Gen  7 | Avg Fitness: 0.7661 | Best Fitness: 0.8142\n",
            "Gen  8 | Avg Fitness: 0.7705 | Best Fitness: 0.8142\n",
            "Gen  9 | Avg Fitness: 0.7777 | Best Fitness: 0.8142\n",
            "Gen 10 | Avg Fitness: 0.7706 | Best Fitness: 0.8142\n",
            "\n",
            "Best MLP Configuration Found:\n",
            "  hidden_layer_1: 122\n",
            "  hidden_layer_2: 51\n",
            "  learning_rate_init: 0.028722841335565907\n",
            "  alpha: 0.006702777110862674\n",
            "  batch_size: 78\n",
            "  => Fitness: 0.8142\n",
            "\n",
            "************************************************************\n",
            "Meta-GA Gen 1 Summary:\n",
            "  Avg Fitness: 0.8180\n",
            "  Best Fitness: 0.8314\n",
            "************************************************************\n",
            "\n",
            "************************************************************\n",
            "META-GA Generation 2/3\n",
            "************************************************************\n",
            "\n",
            "Evaluating GA Config 1/6:\n",
            "  Population: 28, Generations: 21\n",
            "  Mutation: 0.200, Crossover: 0.844\n",
            "\n",
            "============================================================\n",
            "Inner GA: Optimizing MLP Hyperparameters\n",
            "Population Size: 28, Generations: 21\n",
            "Mutation Rate: 0.200, Crossover Rate: 0.844\n",
            "============================================================\n",
            "Gen  1 | Avg Fitness: 0.7586 | Best Fitness: 0.8100\n",
            "Gen  2 | Avg Fitness: 0.7698 | Best Fitness: 0.8100\n",
            "Gen  3 | Avg Fitness: 0.7677 | Best Fitness: 0.8100\n",
            "Gen  4 | Avg Fitness: 0.7657 | Best Fitness: 0.8100\n",
            "Gen  5 | Avg Fitness: 0.7779 | Best Fitness: 0.8100\n",
            "Gen  6 | Avg Fitness: 0.7797 | Best Fitness: 0.8100\n",
            "Gen  7 | Avg Fitness: 0.7843 | Best Fitness: 0.8171\n",
            "Gen  8 | Avg Fitness: 0.7851 | Best Fitness: 0.8171\n",
            "Gen  9 | Avg Fitness: 0.7823 | Best Fitness: 0.8171\n",
            "Gen 10 | Avg Fitness: 0.7717 | Best Fitness: 0.8171\n",
            "Gen 11 | Avg Fitness: 0.7844 | Best Fitness: 0.8171\n",
            "Gen 12 | Avg Fitness: 0.7826 | Best Fitness: 0.8171\n",
            "Gen 13 | Avg Fitness: 0.7825 | Best Fitness: 0.8171\n",
            "Gen 14 | Avg Fitness: 0.7794 | Best Fitness: 0.8171\n",
            "Gen 15 | Avg Fitness: 0.7724 | Best Fitness: 0.8171\n",
            "Gen 16 | Avg Fitness: 0.7747 | Best Fitness: 0.8171\n",
            "Gen 17 | Avg Fitness: 0.7721 | Best Fitness: 0.8171\n",
            "Gen 18 | Avg Fitness: 0.7728 | Best Fitness: 0.8217\n",
            "Gen 19 | Avg Fitness: 0.7702 | Best Fitness: 0.8217\n",
            "Gen 20 | Avg Fitness: 0.7712 | Best Fitness: 0.8217\n",
            "Gen 21 | Avg Fitness: 0.7652 | Best Fitness: 0.8217\n",
            "\n",
            "Best MLP Configuration Found:\n",
            "  hidden_layer_1: 62\n",
            "  hidden_layer_2: 114\n",
            "  learning_rate_init: 0.02524674333357602\n",
            "  alpha: 0.00861010179312271\n",
            "  batch_size: 85\n",
            "  => Fitness: 0.8217\n",
            "\n",
            "Evaluating GA Config 2/6:\n",
            "  Population: 23, Generations: 12\n",
            "  Mutation: 0.292, Crossover: 0.830\n",
            "\n",
            "============================================================\n",
            "Inner GA: Optimizing MLP Hyperparameters\n",
            "Population Size: 23, Generations: 12\n",
            "Mutation Rate: 0.292, Crossover Rate: 0.830\n",
            "============================================================\n",
            "Gen  1 | Avg Fitness: 0.7605 | Best Fitness: 0.8025\n",
            "Gen  2 | Avg Fitness: 0.7555 | Best Fitness: 0.8055\n",
            "Gen  3 | Avg Fitness: 0.7628 | Best Fitness: 0.8106\n",
            "Gen  4 | Avg Fitness: 0.7634 | Best Fitness: 0.8106\n",
            "Gen  5 | Avg Fitness: 0.7700 | Best Fitness: 0.8142\n",
            "Gen  6 | Avg Fitness: 0.7582 | Best Fitness: 0.8171\n",
            "Gen  7 | Avg Fitness: 0.7593 | Best Fitness: 0.8171\n",
            "Gen  8 | Avg Fitness: 0.7659 | Best Fitness: 0.8171\n",
            "Gen  9 | Avg Fitness: 0.7571 | Best Fitness: 0.8171\n",
            "Gen 10 | Avg Fitness: 0.7657 | Best Fitness: 0.8171\n",
            "Gen 11 | Avg Fitness: 0.7587 | Best Fitness: 0.8171\n",
            "Gen 12 | Avg Fitness: 0.7637 | Best Fitness: 0.8171\n",
            "\n",
            "Best MLP Configuration Found:\n",
            "  hidden_layer_1: 71\n",
            "  hidden_layer_2: 27\n",
            "  learning_rate_init: 0.0451595708276517\n",
            "  alpha: 0.0011358759992103947\n",
            "  batch_size: 63\n",
            "  => Fitness: 0.8171\n",
            "\n",
            "Evaluating GA Config 3/6:\n",
            "  Population: 28, Generations: 21\n",
            "  Mutation: 0.167, Crossover: 0.844\n",
            "\n",
            "============================================================\n",
            "Inner GA: Optimizing MLP Hyperparameters\n",
            "Population Size: 28, Generations: 21\n",
            "Mutation Rate: 0.167, Crossover Rate: 0.844\n",
            "============================================================\n",
            "Gen  1 | Avg Fitness: 0.7448 | Best Fitness: 0.7795\n",
            "Gen  2 | Avg Fitness: 0.7549 | Best Fitness: 0.8025\n",
            "Gen  3 | Avg Fitness: 0.7658 | Best Fitness: 0.8025\n",
            "Gen  4 | Avg Fitness: 0.7635 | Best Fitness: 0.8025\n",
            "Gen  5 | Avg Fitness: 0.7612 | Best Fitness: 0.8025\n",
            "Gen  6 | Avg Fitness: 0.7667 | Best Fitness: 0.8025\n",
            "Gen  7 | Avg Fitness: 0.7753 | Best Fitness: 0.8025\n",
            "Gen  8 | Avg Fitness: 0.7734 | Best Fitness: 0.8025\n",
            "Gen  9 | Avg Fitness: 0.7702 | Best Fitness: 0.8025\n",
            "Gen 10 | Avg Fitness: 0.7724 | Best Fitness: 0.8025\n",
            "Gen 11 | Avg Fitness: 0.7741 | Best Fitness: 0.8055\n",
            "Gen 12 | Avg Fitness: 0.7781 | Best Fitness: 0.8079\n",
            "Gen 13 | Avg Fitness: 0.7863 | Best Fitness: 0.8171\n",
            "Gen 14 | Avg Fitness: 0.7839 | Best Fitness: 0.8171\n",
            "Gen 15 | Avg Fitness: 0.7856 | Best Fitness: 0.8171\n",
            "Gen 16 | Avg Fitness: 0.7774 | Best Fitness: 0.8171\n",
            "Gen 17 | Avg Fitness: 0.7825 | Best Fitness: 0.8171\n",
            "Gen 18 | Avg Fitness: 0.7855 | Best Fitness: 0.8171\n",
            "Gen 19 | Avg Fitness: 0.7891 | Best Fitness: 0.8314\n",
            "Gen 20 | Avg Fitness: 0.7887 | Best Fitness: 0.8314\n",
            "Gen 21 | Avg Fitness: 0.7891 | Best Fitness: 0.8314\n",
            "\n",
            "Best MLP Configuration Found:\n",
            "  hidden_layer_1: 42\n",
            "  hidden_layer_2: 96\n",
            "  learning_rate_init: 0.04493372547573149\n",
            "  alpha: 0.006175610217558707\n",
            "  batch_size: 61\n",
            "  => Fitness: 0.8314\n",
            "\n",
            "Evaluating GA Config 4/6:\n",
            "  Population: 21, Generations: 21\n",
            "  Mutation: 0.179, Crossover: 0.844\n",
            "\n",
            "============================================================\n",
            "Inner GA: Optimizing MLP Hyperparameters\n",
            "Population Size: 21, Generations: 21\n",
            "Mutation Rate: 0.179, Crossover Rate: 0.844\n",
            "============================================================\n",
            "Gen  1 | Avg Fitness: 0.7525 | Best Fitness: 0.8142\n",
            "Gen  2 | Avg Fitness: 0.7661 | Best Fitness: 0.8142\n",
            "Gen  3 | Avg Fitness: 0.7740 | Best Fitness: 0.8142\n",
            "Gen  4 | Avg Fitness: 0.7721 | Best Fitness: 0.8142\n",
            "Gen  5 | Avg Fitness: 0.7807 | Best Fitness: 0.8142\n",
            "Gen  6 | Avg Fitness: 0.7800 | Best Fitness: 0.8142\n",
            "Gen  7 | Avg Fitness: 0.7781 | Best Fitness: 0.8258\n",
            "Gen  8 | Avg Fitness: 0.7962 | Best Fitness: 0.8258\n",
            "Gen  9 | Avg Fitness: 0.8006 | Best Fitness: 0.8258\n",
            "Gen 10 | Avg Fitness: 0.7957 | Best Fitness: 0.8258\n",
            "Gen 11 | Avg Fitness: 0.7969 | Best Fitness: 0.8258\n",
            "Gen 12 | Avg Fitness: 0.8119 | Best Fitness: 0.8258\n",
            "Gen 13 | Avg Fitness: 0.7757 | Best Fitness: 0.8258\n",
            "Gen 14 | Avg Fitness: 0.7963 | Best Fitness: 0.8258\n",
            "Gen 15 | Avg Fitness: 0.7895 | Best Fitness: 0.8258\n",
            "Gen 16 | Avg Fitness: 0.7937 | Best Fitness: 0.8258\n",
            "Gen 17 | Avg Fitness: 0.7996 | Best Fitness: 0.8258\n",
            "Gen 18 | Avg Fitness: 0.8042 | Best Fitness: 0.8258\n",
            "Gen 19 | Avg Fitness: 0.8009 | Best Fitness: 0.8258\n",
            "Gen 20 | Avg Fitness: 0.7963 | Best Fitness: 0.8258\n",
            "Gen 21 | Avg Fitness: 0.8000 | Best Fitness: 0.8258\n",
            "\n",
            "Best MLP Configuration Found:\n",
            "  hidden_layer_1: 87\n",
            "  hidden_layer_2: 107\n",
            "  learning_rate_init: 0.009348034875598252\n",
            "  alpha: 0.004158622607068457\n",
            "  batch_size: 19\n",
            "  => Fitness: 0.8258\n",
            "\n",
            "Evaluating GA Config 5/6:\n",
            "  Population: 35, Generations: 28\n",
            "  Mutation: 0.200, Crossover: 0.781\n",
            "\n",
            "============================================================\n",
            "Inner GA: Optimizing MLP Hyperparameters\n",
            "Population Size: 35, Generations: 28\n",
            "Mutation Rate: 0.200, Crossover Rate: 0.781\n",
            "============================================================\n",
            "Gen  1 | Avg Fitness: 0.7520 | Best Fitness: 0.7991\n",
            "Gen  2 | Avg Fitness: 0.7599 | Best Fitness: 0.8106\n",
            "Gen  3 | Avg Fitness: 0.7577 | Best Fitness: 0.8106\n",
            "Gen  4 | Avg Fitness: 0.7661 | Best Fitness: 0.8106\n",
            "Gen  5 | Avg Fitness: 0.7623 | Best Fitness: 0.8171\n",
            "Gen  6 | Avg Fitness: 0.7676 | Best Fitness: 0.8171\n",
            "Gen  7 | Avg Fitness: 0.7637 | Best Fitness: 0.8171\n",
            "Gen  8 | Avg Fitness: 0.7654 | Best Fitness: 0.8171\n",
            "Gen  9 | Avg Fitness: 0.7738 | Best Fitness: 0.8171\n",
            "Gen 10 | Avg Fitness: 0.7688 | Best Fitness: 0.8171\n",
            "Gen 11 | Avg Fitness: 0.7673 | Best Fitness: 0.8171\n",
            "Gen 12 | Avg Fitness: 0.7669 | Best Fitness: 0.8171\n",
            "Gen 13 | Avg Fitness: 0.7659 | Best Fitness: 0.8171\n",
            "Gen 14 | Avg Fitness: 0.7682 | Best Fitness: 0.8171\n",
            "Gen 15 | Avg Fitness: 0.7736 | Best Fitness: 0.8171\n",
            "Gen 16 | Avg Fitness: 0.7697 | Best Fitness: 0.8171\n",
            "Gen 17 | Avg Fitness: 0.7625 | Best Fitness: 0.8171\n",
            "Gen 18 | Avg Fitness: 0.7739 | Best Fitness: 0.8171\n",
            "Gen 19 | Avg Fitness: 0.7752 | Best Fitness: 0.8171\n",
            "Gen 20 | Avg Fitness: 0.7735 | Best Fitness: 0.8171\n",
            "Gen 21 | Avg Fitness: 0.7770 | Best Fitness: 0.8171\n",
            "Gen 22 | Avg Fitness: 0.7704 | Best Fitness: 0.8171\n",
            "Gen 23 | Avg Fitness: 0.7568 | Best Fitness: 0.8171\n",
            "Gen 24 | Avg Fitness: 0.7668 | Best Fitness: 0.8171\n",
            "Gen 25 | Avg Fitness: 0.7646 | Best Fitness: 0.8171\n",
            "Gen 26 | Avg Fitness: 0.7627 | Best Fitness: 0.8171\n",
            "Gen 27 | Avg Fitness: 0.7719 | Best Fitness: 0.8171\n",
            "Gen 28 | Avg Fitness: 0.7648 | Best Fitness: 0.8171\n",
            "\n",
            "Best MLP Configuration Found:\n",
            "  hidden_layer_1: 24\n",
            "  hidden_layer_2: 128\n",
            "  learning_rate_init: 0.02665220522137522\n",
            "  alpha: 0.006058801640960127\n",
            "  batch_size: 93\n",
            "  => Fitness: 0.8171\n",
            "\n",
            "Evaluating GA Config 6/6:\n",
            "  Population: 28, Generations: 25\n",
            "  Mutation: 0.145, Crossover: 0.844\n",
            "\n",
            "============================================================\n",
            "Inner GA: Optimizing MLP Hyperparameters\n",
            "Population Size: 28, Generations: 25\n",
            "Mutation Rate: 0.145, Crossover Rate: 0.844\n",
            "============================================================\n",
            "Gen  1 | Avg Fitness: 0.7537 | Best Fitness: 0.8025\n",
            "Gen  2 | Avg Fitness: 0.7582 | Best Fitness: 0.8025\n",
            "Gen  3 | Avg Fitness: 0.7606 | Best Fitness: 0.8025\n",
            "Gen  4 | Avg Fitness: 0.7671 | Best Fitness: 0.8025\n",
            "Gen  5 | Avg Fitness: 0.7612 | Best Fitness: 0.8025\n",
            "Gen  6 | Avg Fitness: 0.7640 | Best Fitness: 0.8025\n",
            "Gen  7 | Avg Fitness: 0.7663 | Best Fitness: 0.8106\n",
            "Gen  8 | Avg Fitness: 0.7667 | Best Fitness: 0.8106\n",
            "Gen  9 | Avg Fitness: 0.7738 | Best Fitness: 0.8106\n",
            "Gen 10 | Avg Fitness: 0.7768 | Best Fitness: 0.8106\n",
            "Gen 11 | Avg Fitness: 0.7658 | Best Fitness: 0.8106\n",
            "Gen 12 | Avg Fitness: 0.7742 | Best Fitness: 0.8106\n",
            "Gen 13 | Avg Fitness: 0.7798 | Best Fitness: 0.8106\n",
            "Gen 14 | Avg Fitness: 0.7831 | Best Fitness: 0.8106\n",
            "Gen 15 | Avg Fitness: 0.7843 | Best Fitness: 0.8106\n",
            "Gen 16 | Avg Fitness: 0.7730 | Best Fitness: 0.8106\n",
            "Gen 17 | Avg Fitness: 0.7789 | Best Fitness: 0.8106\n",
            "Gen 18 | Avg Fitness: 0.7861 | Best Fitness: 0.8106\n",
            "Gen 19 | Avg Fitness: 0.7822 | Best Fitness: 0.8106\n",
            "Gen 20 | Avg Fitness: 0.7766 | Best Fitness: 0.8106\n",
            "Gen 21 | Avg Fitness: 0.7854 | Best Fitness: 0.8106\n",
            "Gen 22 | Avg Fitness: 0.7815 | Best Fitness: 0.8106\n",
            "Gen 23 | Avg Fitness: 0.7864 | Best Fitness: 0.8106\n",
            "Gen 24 | Avg Fitness: 0.7868 | Best Fitness: 0.8106\n",
            "Gen 25 | Avg Fitness: 0.7857 | Best Fitness: 0.8106\n",
            "\n",
            "Best MLP Configuration Found:\n",
            "  hidden_layer_1: 38\n",
            "  hidden_layer_2: 6\n",
            "  learning_rate_init: 0.05342924662026396\n",
            "  alpha: 0.0009776640486891112\n",
            "  batch_size: 49\n",
            "  => Fitness: 0.8106\n",
            "\n",
            "************************************************************\n",
            "Meta-GA Gen 2 Summary:\n",
            "  Avg Fitness: 0.8206\n",
            "  Best Fitness: 0.8314\n",
            "************************************************************\n",
            "\n",
            "************************************************************\n",
            "META-GA Generation 3/3\n",
            "************************************************************\n",
            "\n",
            "Evaluating GA Config 1/6:\n",
            "  Population: 28, Generations: 21\n",
            "  Mutation: 0.200, Crossover: 0.844\n",
            "\n",
            "============================================================\n",
            "Inner GA: Optimizing MLP Hyperparameters\n",
            "Population Size: 28, Generations: 21\n",
            "Mutation Rate: 0.200, Crossover Rate: 0.844\n",
            "============================================================\n",
            "Gen  1 | Avg Fitness: 0.7532 | Best Fitness: 0.7910\n",
            "Gen  2 | Avg Fitness: 0.7523 | Best Fitness: 0.7910\n",
            "Gen  3 | Avg Fitness: 0.7678 | Best Fitness: 0.8025\n",
            "Gen  4 | Avg Fitness: 0.7607 | Best Fitness: 0.8106\n",
            "Gen  5 | Avg Fitness: 0.7678 | Best Fitness: 0.8142\n",
            "Gen  6 | Avg Fitness: 0.7714 | Best Fitness: 0.8142\n",
            "Gen  7 | Avg Fitness: 0.7727 | Best Fitness: 0.8217\n",
            "Gen  8 | Avg Fitness: 0.7745 | Best Fitness: 0.8217\n",
            "Gen  9 | Avg Fitness: 0.7676 | Best Fitness: 0.8217\n",
            "Gen 10 | Avg Fitness: 0.7721 | Best Fitness: 0.8217\n",
            "Gen 11 | Avg Fitness: 0.7701 | Best Fitness: 0.8217\n",
            "Gen 12 | Avg Fitness: 0.7783 | Best Fitness: 0.8217\n",
            "Gen 13 | Avg Fitness: 0.7758 | Best Fitness: 0.8217\n",
            "Gen 14 | Avg Fitness: 0.7777 | Best Fitness: 0.8217\n",
            "Gen 15 | Avg Fitness: 0.7779 | Best Fitness: 0.8217\n",
            "Gen 16 | Avg Fitness: 0.7837 | Best Fitness: 0.8289\n",
            "Gen 17 | Avg Fitness: 0.7848 | Best Fitness: 0.8289\n",
            "Gen 18 | Avg Fitness: 0.7848 | Best Fitness: 0.8289\n",
            "Gen 19 | Avg Fitness: 0.7917 | Best Fitness: 0.8289\n",
            "Gen 20 | Avg Fitness: 0.7789 | Best Fitness: 0.8289\n",
            "Gen 21 | Avg Fitness: 0.7724 | Best Fitness: 0.8289\n",
            "\n",
            "Best MLP Configuration Found:\n",
            "  hidden_layer_1: 81\n",
            "  hidden_layer_2: 122\n",
            "  learning_rate_init: 0.029549735737309603\n",
            "  alpha: 0.005515491187529001\n",
            "  batch_size: 115\n",
            "  => Fitness: 0.8289\n",
            "\n",
            "Evaluating GA Config 2/6:\n",
            "  Population: 28, Generations: 21\n",
            "  Mutation: 0.167, Crossover: 0.844\n",
            "\n",
            "============================================================\n",
            "Inner GA: Optimizing MLP Hyperparameters\n",
            "Population Size: 28, Generations: 21\n",
            "Mutation Rate: 0.167, Crossover Rate: 0.844\n",
            "============================================================\n",
            "Gen  1 | Avg Fitness: 0.7633 | Best Fitness: 0.8142\n",
            "Gen  2 | Avg Fitness: 0.7674 | Best Fitness: 0.8142\n",
            "Gen  3 | Avg Fitness: 0.7652 | Best Fitness: 0.8142\n",
            "Gen  4 | Avg Fitness: 0.7619 | Best Fitness: 0.8142\n",
            "Gen  5 | Avg Fitness: 0.7630 | Best Fitness: 0.8142\n",
            "Gen  6 | Avg Fitness: 0.7647 | Best Fitness: 0.8142\n",
            "Gen  7 | Avg Fitness: 0.7806 | Best Fitness: 0.8258\n",
            "Gen  8 | Avg Fitness: 0.7736 | Best Fitness: 0.8258\n",
            "Gen  9 | Avg Fitness: 0.7812 | Best Fitness: 0.8258\n",
            "Gen 10 | Avg Fitness: 0.7921 | Best Fitness: 0.8258\n",
            "Gen 11 | Avg Fitness: 0.7921 | Best Fitness: 0.8258\n",
            "Gen 12 | Avg Fitness: 0.7952 | Best Fitness: 0.8258\n",
            "Gen 13 | Avg Fitness: 0.7866 | Best Fitness: 0.8258\n",
            "Gen 14 | Avg Fitness: 0.8013 | Best Fitness: 0.8258\n",
            "Gen 15 | Avg Fitness: 0.8023 | Best Fitness: 0.8258\n",
            "Gen 16 | Avg Fitness: 0.7995 | Best Fitness: 0.8258\n",
            "Gen 17 | Avg Fitness: 0.7922 | Best Fitness: 0.8258\n",
            "Gen 18 | Avg Fitness: 0.7760 | Best Fitness: 0.8258\n",
            "Gen 19 | Avg Fitness: 0.7935 | Best Fitness: 0.8258\n",
            "Gen 20 | Avg Fitness: 0.8016 | Best Fitness: 0.8258\n",
            "Gen 21 | Avg Fitness: 0.7928 | Best Fitness: 0.8258\n",
            "\n",
            "Best MLP Configuration Found:\n",
            "  hidden_layer_1: 14\n",
            "  hidden_layer_2: 83\n",
            "  learning_rate_init: 0.014178124850095963\n",
            "  alpha: 0.008537699190729138\n",
            "  batch_size: 114\n",
            "  => Fitness: 0.8258\n",
            "\n",
            "Evaluating GA Config 3/6:\n",
            "  Population: 35, Generations: 27\n",
            "  Mutation: 0.187, Crossover: 0.781\n",
            "\n",
            "============================================================\n",
            "Inner GA: Optimizing MLP Hyperparameters\n",
            "Population Size: 35, Generations: 27\n",
            "Mutation Rate: 0.187, Crossover Rate: 0.781\n",
            "============================================================\n",
            "Gen  1 | Avg Fitness: 0.7545 | Best Fitness: 0.7991\n",
            "Gen  2 | Avg Fitness: 0.7553 | Best Fitness: 0.7991\n",
            "Gen  3 | Avg Fitness: 0.7627 | Best Fitness: 0.7991\n",
            "Gen  4 | Avg Fitness: 0.7698 | Best Fitness: 0.8055\n",
            "Gen  5 | Avg Fitness: 0.7581 | Best Fitness: 0.8055\n",
            "Gen  6 | Avg Fitness: 0.7649 | Best Fitness: 0.8142\n",
            "Gen  7 | Avg Fitness: 0.7749 | Best Fitness: 0.8142\n",
            "Gen  8 | Avg Fitness: 0.7735 | Best Fitness: 0.8142\n",
            "Gen  9 | Avg Fitness: 0.7757 | Best Fitness: 0.8142\n",
            "Gen 10 | Avg Fitness: 0.7724 | Best Fitness: 0.8142\n",
            "Gen 11 | Avg Fitness: 0.7756 | Best Fitness: 0.8142\n",
            "Gen 12 | Avg Fitness: 0.7752 | Best Fitness: 0.8142\n",
            "Gen 13 | Avg Fitness: 0.7798 | Best Fitness: 0.8142\n",
            "Gen 14 | Avg Fitness: 0.7842 | Best Fitness: 0.8142\n",
            "Gen 15 | Avg Fitness: 0.7745 | Best Fitness: 0.8171\n",
            "Gen 16 | Avg Fitness: 0.7842 | Best Fitness: 0.8171\n",
            "Gen 17 | Avg Fitness: 0.7861 | Best Fitness: 0.8171\n",
            "Gen 18 | Avg Fitness: 0.7814 | Best Fitness: 0.8171\n",
            "Gen 19 | Avg Fitness: 0.7897 | Best Fitness: 0.8171\n",
            "Gen 20 | Avg Fitness: 0.7849 | Best Fitness: 0.8171\n",
            "Gen 21 | Avg Fitness: 0.7904 | Best Fitness: 0.8171\n",
            "Gen 22 | Avg Fitness: 0.7907 | Best Fitness: 0.8171\n",
            "Gen 23 | Avg Fitness: 0.7833 | Best Fitness: 0.8171\n",
            "Gen 24 | Avg Fitness: 0.7898 | Best Fitness: 0.8289\n",
            "Gen 25 | Avg Fitness: 0.7927 | Best Fitness: 0.8289\n",
            "Gen 26 | Avg Fitness: 0.7957 | Best Fitness: 0.8289\n",
            "Gen 27 | Avg Fitness: 0.7997 | Best Fitness: 0.8289\n",
            "\n",
            "Best MLP Configuration Found:\n",
            "  hidden_layer_1: 186\n",
            "  hidden_layer_2: 126\n",
            "  learning_rate_init: 0.018113267609351877\n",
            "  alpha: 0.0040523740832513495\n",
            "  batch_size: 34\n",
            "  => Fitness: 0.8289\n",
            "\n",
            "Evaluating GA Config 4/6:\n",
            "  Population: 21, Generations: 21\n",
            "  Mutation: 0.200, Crossover: 0.844\n",
            "\n",
            "============================================================\n",
            "Inner GA: Optimizing MLP Hyperparameters\n",
            "Population Size: 21, Generations: 21\n",
            "Mutation Rate: 0.200, Crossover Rate: 0.844\n",
            "============================================================\n",
            "Gen  1 | Avg Fitness: 0.7438 | Best Fitness: 0.7762\n",
            "Gen  2 | Avg Fitness: 0.7549 | Best Fitness: 0.8025\n",
            "Gen  3 | Avg Fitness: 0.7553 | Best Fitness: 0.8025\n",
            "Gen  4 | Avg Fitness: 0.7613 | Best Fitness: 0.8025\n",
            "Gen  5 | Avg Fitness: 0.7643 | Best Fitness: 0.8025\n",
            "Gen  6 | Avg Fitness: 0.7680 | Best Fitness: 0.8171\n",
            "Gen  7 | Avg Fitness: 0.7729 | Best Fitness: 0.8171\n",
            "Gen  8 | Avg Fitness: 0.7779 | Best Fitness: 0.8171\n",
            "Gen  9 | Avg Fitness: 0.7658 | Best Fitness: 0.8171\n",
            "Gen 10 | Avg Fitness: 0.7709 | Best Fitness: 0.8171\n",
            "Gen 11 | Avg Fitness: 0.7799 | Best Fitness: 0.8171\n",
            "Gen 12 | Avg Fitness: 0.7750 | Best Fitness: 0.8171\n",
            "Gen 13 | Avg Fitness: 0.7803 | Best Fitness: 0.8171\n",
            "Gen 14 | Avg Fitness: 0.7696 | Best Fitness: 0.8171\n",
            "Gen 15 | Avg Fitness: 0.7758 | Best Fitness: 0.8171\n",
            "Gen 16 | Avg Fitness: 0.7836 | Best Fitness: 0.8171\n",
            "Gen 17 | Avg Fitness: 0.7907 | Best Fitness: 0.8171\n",
            "Gen 18 | Avg Fitness: 0.7848 | Best Fitness: 0.8171\n",
            "Gen 19 | Avg Fitness: 0.7912 | Best Fitness: 0.8171\n",
            "Gen 20 | Avg Fitness: 0.7747 | Best Fitness: 0.8171\n",
            "Gen 21 | Avg Fitness: 0.7849 | Best Fitness: 0.8171\n",
            "\n",
            "Best MLP Configuration Found:\n",
            "  hidden_layer_1: 30\n",
            "  hidden_layer_2: 61\n",
            "  learning_rate_init: 0.005879932197695919\n",
            "  alpha: 0.005857982517100577\n",
            "  batch_size: 87\n",
            "  => Fitness: 0.8171\n",
            "\n",
            "Evaluating GA Config 5/6:\n",
            "  Population: 21, Generations: 22\n",
            "  Mutation: 0.169, Crossover: 0.844\n",
            "\n",
            "============================================================\n",
            "Inner GA: Optimizing MLP Hyperparameters\n",
            "Population Size: 21, Generations: 22\n",
            "Mutation Rate: 0.169, Crossover Rate: 0.844\n",
            "============================================================\n",
            "Gen  1 | Avg Fitness: 0.7542 | Best Fitness: 0.8025\n",
            "Gen  2 | Avg Fitness: 0.7688 | Best Fitness: 0.8196\n",
            "Gen  3 | Avg Fitness: 0.7639 | Best Fitness: 0.8196\n",
            "Gen  4 | Avg Fitness: 0.7680 | Best Fitness: 0.8196\n",
            "Gen  5 | Avg Fitness: 0.7766 | Best Fitness: 0.8196\n",
            "Gen  6 | Avg Fitness: 0.7831 | Best Fitness: 0.8196\n",
            "Gen  7 | Avg Fitness: 0.7839 | Best Fitness: 0.8196\n",
            "Gen  8 | Avg Fitness: 0.7770 | Best Fitness: 0.8196\n",
            "Gen  9 | Avg Fitness: 0.7881 | Best Fitness: 0.8196\n",
            "Gen 10 | Avg Fitness: 0.7896 | Best Fitness: 0.8196\n",
            "Gen 11 | Avg Fitness: 0.7914 | Best Fitness: 0.8196\n",
            "Gen 12 | Avg Fitness: 0.7859 | Best Fitness: 0.8196\n",
            "Gen 13 | Avg Fitness: 0.7819 | Best Fitness: 0.8196\n",
            "Gen 14 | Avg Fitness: 0.7805 | Best Fitness: 0.8196\n",
            "Gen 15 | Avg Fitness: 0.7925 | Best Fitness: 0.8196\n",
            "Gen 16 | Avg Fitness: 0.7905 | Best Fitness: 0.8196\n",
            "Gen 17 | Avg Fitness: 0.7952 | Best Fitness: 0.8196\n",
            "Gen 18 | Avg Fitness: 0.7987 | Best Fitness: 0.8196\n",
            "Gen 19 | Avg Fitness: 0.7840 | Best Fitness: 0.8196\n",
            "Gen 20 | Avg Fitness: 0.7784 | Best Fitness: 0.8196\n",
            "Gen 21 | Avg Fitness: 0.7820 | Best Fitness: 0.8196\n",
            "Gen 22 | Avg Fitness: 0.7865 | Best Fitness: 0.8196\n",
            "\n",
            "Best MLP Configuration Found:\n",
            "  hidden_layer_1: 112\n",
            "  hidden_layer_2: 104\n",
            "  learning_rate_init: 0.03827387256000685\n",
            "  alpha: 0.00594789537990932\n",
            "  batch_size: 29\n",
            "  => Fitness: 0.8196\n",
            "\n",
            "Evaluating GA Config 6/6:\n",
            "  Population: 28, Generations: 28\n",
            "  Mutation: 0.183, Crossover: 0.844\n",
            "\n",
            "============================================================\n",
            "Inner GA: Optimizing MLP Hyperparameters\n",
            "Population Size: 28, Generations: 28\n",
            "Mutation Rate: 0.183, Crossover Rate: 0.844\n",
            "============================================================\n",
            "Gen  1 | Avg Fitness: 0.7464 | Best Fitness: 0.7795\n",
            "Gen  2 | Avg Fitness: 0.7576 | Best Fitness: 0.8025\n",
            "Gen  3 | Avg Fitness: 0.7562 | Best Fitness: 0.8025\n",
            "Gen  4 | Avg Fitness: 0.7631 | Best Fitness: 0.8025\n",
            "Gen  5 | Avg Fitness: 0.7719 | Best Fitness: 0.8025\n",
            "Gen  6 | Avg Fitness: 0.7717 | Best Fitness: 0.8142\n",
            "Gen  7 | Avg Fitness: 0.7679 | Best Fitness: 0.8142\n",
            "Gen  8 | Avg Fitness: 0.7680 | Best Fitness: 0.8142\n",
            "Gen  9 | Avg Fitness: 0.7721 | Best Fitness: 0.8142\n",
            "Gen 10 | Avg Fitness: 0.7769 | Best Fitness: 0.8142\n",
            "Gen 11 | Avg Fitness: 0.7652 | Best Fitness: 0.8142\n",
            "Gen 12 | Avg Fitness: 0.7706 | Best Fitness: 0.8142\n",
            "Gen 13 | Avg Fitness: 0.7781 | Best Fitness: 0.8171\n",
            "Gen 14 | Avg Fitness: 0.7710 | Best Fitness: 0.8171\n",
            "Gen 15 | Avg Fitness: 0.7757 | Best Fitness: 0.8171\n",
            "Gen 16 | Avg Fitness: 0.7710 | Best Fitness: 0.8171\n",
            "Gen 17 | Avg Fitness: 0.7694 | Best Fitness: 0.8171\n",
            "Gen 18 | Avg Fitness: 0.7714 | Best Fitness: 0.8171\n",
            "Gen 19 | Avg Fitness: 0.7644 | Best Fitness: 0.8171\n",
            "Gen 20 | Avg Fitness: 0.7642 | Best Fitness: 0.8171\n",
            "Gen 21 | Avg Fitness: 0.7793 | Best Fitness: 0.8171\n",
            "Gen 22 | Avg Fitness: 0.7722 | Best Fitness: 0.8196\n",
            "Gen 23 | Avg Fitness: 0.7785 | Best Fitness: 0.8196\n",
            "Gen 24 | Avg Fitness: 0.7698 | Best Fitness: 0.8196\n",
            "Gen 25 | Avg Fitness: 0.7755 | Best Fitness: 0.8196\n",
            "Gen 26 | Avg Fitness: 0.7707 | Best Fitness: 0.8196\n",
            "Gen 27 | Avg Fitness: 0.7709 | Best Fitness: 0.8196\n",
            "Gen 28 | Avg Fitness: 0.7800 | Best Fitness: 0.8196\n",
            "\n",
            "Best MLP Configuration Found:\n",
            "  hidden_layer_1: 186\n",
            "  hidden_layer_2: 27\n",
            "  learning_rate_init: 0.025098709926229403\n",
            "  alpha: 0.004470895577394513\n",
            "  batch_size: 110\n",
            "  => Fitness: 0.8196\n",
            "\n",
            "************************************************************\n",
            "Meta-GA Gen 3 Summary:\n",
            "  Avg Fitness: 0.8233\n",
            "  Best Fitness: 0.8314\n",
            "************************************************************\n",
            "\n",
            "############################################################\n",
            "FINAL RESULTS - BEST GA HYPERPARAMETERS FOUND:\n",
            "############################################################\n",
            "  population_size: 28\n",
            "  generations: 21\n",
            "  mutation_rate: 0.20023637113442977\n",
            "  crossover_rate: 0.8436279515484637\n",
            "\n",
            "Best validation fitness achieved: 0.8314\n",
            "\n",
            "============================================================\n",
            "FINAL RUN: Training MLP with Optimized Hyperparameters\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Inner GA: Optimizing MLP Hyperparameters\n",
            "Population Size: 28, Generations: 21\n",
            "Mutation Rate: 0.200, Crossover Rate: 0.844\n",
            "============================================================\n",
            "Gen  1 | Avg Fitness: 0.7537 | Best Fitness: 0.8055\n",
            "Gen  2 | Avg Fitness: 0.7617 | Best Fitness: 0.8055\n",
            "Gen  3 | Avg Fitness: 0.7724 | Best Fitness: 0.8055\n",
            "Gen  4 | Avg Fitness: 0.7700 | Best Fitness: 0.8055\n",
            "Gen  5 | Avg Fitness: 0.7575 | Best Fitness: 0.8055\n",
            "Gen  6 | Avg Fitness: 0.7723 | Best Fitness: 0.8055\n",
            "Gen  7 | Avg Fitness: 0.7663 | Best Fitness: 0.8055\n",
            "Gen  8 | Avg Fitness: 0.7667 | Best Fitness: 0.8055\n",
            "Gen  9 | Avg Fitness: 0.7572 | Best Fitness: 0.8055\n",
            "Gen 10 | Avg Fitness: 0.7636 | Best Fitness: 0.8055\n",
            "Gen 11 | Avg Fitness: 0.7703 | Best Fitness: 0.8055\n",
            "Gen 12 | Avg Fitness: 0.7708 | Best Fitness: 0.8055\n",
            "Gen 13 | Avg Fitness: 0.7630 | Best Fitness: 0.8055\n",
            "Gen 14 | Avg Fitness: 0.7649 | Best Fitness: 0.8055\n",
            "Gen 15 | Avg Fitness: 0.7645 | Best Fitness: 0.8079\n",
            "Gen 16 | Avg Fitness: 0.7616 | Best Fitness: 0.8079\n",
            "Gen 17 | Avg Fitness: 0.7665 | Best Fitness: 0.8196\n",
            "Gen 18 | Avg Fitness: 0.7717 | Best Fitness: 0.8196\n",
            "Gen 19 | Avg Fitness: 0.7706 | Best Fitness: 0.8196\n",
            "Gen 20 | Avg Fitness: 0.7683 | Best Fitness: 0.8196\n",
            "Gen 21 | Avg Fitness: 0.7683 | Best Fitness: 0.8196\n",
            "\n",
            "Best MLP Configuration Found:\n",
            "  hidden_layer_1: 60\n",
            "  hidden_layer_2: 48\n",
            "  learning_rate_init: 0.042596489061640326\n",
            "  alpha: 0.004585286048407282\n",
            "  batch_size: 33\n",
            "\n",
            "============================================================\n",
            "FINAL MODEL EVALUATION ON TEST SET\n",
            "============================================================\n",
            "\n",
            "Test Set Performance:\n",
            "  Accuracy: 0.6800\n",
            "  F1 Score: 0.6620\n",
            "  ROC AUC:  0.5438\n",
            "\n",
            "============================================================\n",
            "OPTIMIZATION COMPLETE!\n",
            "============================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wgC31w1RN-xz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMTLNiQ/nxjw4xHbLjNul1S",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}